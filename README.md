# GLNet for Memory-Efficient Segmentation of Ultra-High Resolution Images

We will provide a complete usage pretrained models for our paper very soon.

Collaborative Global-Local Networks for Memory-Efﬁcient Segmentation of Ultra-High Resolution Images

Wuyang Chen*, Ziyu Jiang*, Zhangyang Wang, Kexin Cui, and Xiaoning Qian

In CVPR 2019 (Oral).

## Overview

Segmentation of ultra-high resolution images is increasingly demanded in a wide range of applications (e.g. urban planning), yet poses signiﬁcant challenges for algorithm efficiency, in particular considering the (GPU) memory limits.

* **Memory-efficient**: training w. only one 1080Ti and inference w. less than 2GB GPU memory, for ultra-high resolution images of up to 30M pixels.

* **High-quality**: GLNet outperforms existing segmentation models on ultra-high resolution images.

<p align="center">
<img src="https://raw.githubusercontent.com/chenwydj/ultra_high_resolution_segmentation/master/docs/images/deep_globe_acc_mem_ext.jpg" alt="Acc_vs_Mem" width="700"/></br>
Inference memory v.s. mIoU on the <a href="https://arxiv.org/abs/1805.06561">DeepGlobe dataset</a>.</br>
<font size="2">Downsampling rates or normalized patch sizes are shown in scale annotations.</font>
</p>

<p align="center">
<img src="https://raw.githubusercontent.com/chenwydj/ultra_high_resolution_segmentation/master/docs/images/examples.jpg" alt="Examples" width="500"/></br>
Ultra-high resolution Datasets: <a href="https://arxiv.org/abs/1805.06561">DeepGlobe</a>, <a href="https://arxiv.org/abs/1710.05006">ISIC</a>, <a href="https://ieeexplore.ieee.org/document/8127684">Inria Aerial</a>
</p>

<p align="center">
<img src="https://raw.githubusercontent.com/chenwydj/ultra_high_resolution_segmentation/master/docs/images/glnet.jpg" alt="GLNet" width="500"/></br>
GLNet: The global and local branch takes downsampled and cropped images, respectively. Deep fea- ture map sharing and feature map regularization enforce our global-local collaboration. The ﬁnal segmentation is generated by aggregating high-level feature maps from two branches. Deep feature map sharing between the global and local branch. At each layer, feature maps with global context and ones with local ﬁne structures are bidirectionally brought together, con- tributing to a complete patch-based deep global-local collabora- tion. The main loss from the aggregated results and two auxiliary losses from two branches form our optimization target.
</p>

GLNet (red dots) integrates both global and local information in a compact way, contributing to a well-balanced trade-off between accuracy and memory usage.*